{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=imamu.png width=700 leight=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color = #0F43B4>Connect four Problem</font> </h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "<h1><font color = #0F43B4>I- Introduction </font></h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>There are many of games that depend on competitive (e.g. tic-tac-toe, Chess, and other games). Those games in which you intend to reduce the level of the opponent which minimize the chance to win and on the other side raise your level and the probability of winning the game. This is the basis for adversarial search algorithms. Among these algorithms are the Minimax algorithm and the Alpha-Beta algorithm.</b>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>تقسم الألعاب إلى فئات مختلفة معتمدة على الهدف من اللعبة و طريقة اللعب و من الفئات المشهورة هي المنافسة حيث يكون الهدف من اللعبة الفوز على الخصم و من أمثلة تلك الألعاب الشطرنج فالكي تفوز يجب أن تقلل إحتمالية فوز خصمك و بالتالي رفع إحتمالية فوزك و من الخوارزميات المستخدمة لحل هذه الألعاب:</b><br>\n",
    "<b>\n",
    "<li> The Minimax algorithm </li>\n",
    "\n",
    "<li> The Alpha-Beta algorithm </li>\n",
    "    </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color = #0F43B4> II- Game Formulation</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We selected the Connect Four game as a problem that we will applay it by  using the Alpha-Beta algorithm. You might be wondering why we are applying the Alpha-Beta algorithm on the Connect Four game. This is because when it is the turn of the machine player to choose a suitable move for its, it needs to search for the best move This is done by the evaluation function.\n",
    "\n",
    "<img src = move.gif width = 500 length=500 >\n",
    "\n",
    "Connect Four game is a board that contains the following : \n",
    "<li>seven columns and six rows, all of which are empty.\n",
    "<li>two players. One of them has a red color and the other one has a yellow color\n",
    "<li>the first player places his piece and then comes the role of the other and so on.\n",
    "<li>The winner of the match is the one who has four pieces next to each other, either vertically, horizontally, or diagonally.\n",
    "<li>But there are some rules that must to following. It is not possible to place a piece in a full column and also it is not possible to place a piece in the top of the column while there is an empty place at the bottom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "نحن أخترنا لعبة \"كونكت فور\" كمشكلة لنطبق عليها خوارزمية ألفا بيتا. ذلك لأن حينما يأتي دور لاعب الألة ليختار حركة مناسبة له فهو يحتاج الى البحث عن أفضل حركة. ذلك عن طريق دالة التقييم.                                                                                                       \n",
    "<b>لعبة كونكت فور هي لعبة لوحية تحتوي على التالي </b> \n",
    "<li>سبعة أعمدة و ستة صفوف جميعها فارغة\n",
    "<li>تقوم اللعبة على أن يكون هناك لاعبين أحدهم يمتلك اللون الأحمر و الأخر يمتلك اللون الأصفر.\n",
    "بحيث يضع اللاعب الاول قطعته ثم يأتي دور اللاعب الأخر وهكذا\n",
    "<li> الفائز في المباراة هو من يمتلك أربع قطع بجانب بعض أما عامودياً او أفقياً او قطرياً\n",
    "<li> لكن هناك بعض القواعد التي يجب أتباعها خلال اللعب. لا يمكن أن تضع قطعة غي عمود ممتلى وأيضا لا يمكن أن تضع قطعة في أعلى العامود بينما يوجد مكان فارغ في الأسفل."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color = #0F43B4> III-Evaluation function</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to determine how good a possible next step that a machine player can take. The machine player chooses the next move based on its quality.the way depends on how much you have to win.<br> The method that we use depends on the position of the piece on the board(e.g. in the middle of a board You have thirteen ways to have four pieces next to each other. Three vertically, four horizontally, and six diagonally).<br> Of course, after collection the machine player's points, the total will be subtracted by the opponent's points. Because on the other side, the opponent is trying to reduce the probability of a machine player winning. Look at the board in Figure 1. Since it is clear that the board contains all the places with a number, this number shows how good this place is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">هناك العديد من الطرق لقياس ما مدى جودة الخطوة التالية المحتملة للاعب الألة. بحيث يختار لاعب الألة الحركة التالية بناء على جودتها ∞. بنسبه الى الطريقة الاخر فهي تعتمد على كم تمتلك طريقة للفوز. اما بموضوع الطريقة التي نستخدمها فهي تعتمد على المكان الذي توجد فيه القطعة(مثلا في منتصف اللوح يمكنك ان تمتلك ثلاثة عشر طريقة للفوز. ثلاثة عامودياً وأربعة أفقاً وسته قطرياً). طبعاً بعد ان تجمع النقط التي متلكها لاعب الألة يجب ان تخص منها عدد النقط التي يمتلكها الخصم. لانه في الجهة المقابله يحاول الخصم جاهداً لتقليل احتمالية فوز لاعب الألة. أنظر الى اللوح في شكل رقم 1. كما هو واضح فان اللوح يحتوي على ارقام لكل موقع في اللوح. تلك الارقام توضح مدى جودة ذلك المكان."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=evaluationBoard.png width=500 leight=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below this you will see a simple  implementation on how the evaluation function works \n",
    "by Python language. As seen in the evaluation board, each place has a value. Every place the opponent owns will reduce the probability of a machine player wins and vice versa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">تحت هذا المحتوى تنفيذ بسيط بلغة البايثون على كيفية عمل دالة التقييم. كما شاهدة في الشكل السابق كل مكان يحتوي على قيمة. فالأماكن التي يمتلكها الخصم سوف تقلل من احنمال فوز لاعب الألة و العكس كذلك."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color = #0F43B4>IV-Alpha-Beta Algorithm</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha-Beta algorithm is a search algorithm that works within the scope of adversarial research. That is, it search for the best case for the machine player. By reducing the opponent's chance of winning and increasing the machine player's chance of winning. Moreover, the Alpha-Beta algorithm takes a short path by cutting parts of the tree through the search process. Those parts that it noticed will not change anything whether or not they are in the search process. A simple example on that, look at Figure 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">خوارزمية ألفا بيتا هي خوارزمية بحث تعمل ضمن نطاق بحث الخصومة. أي انها تسعى الى البحث عن أفضل حالة للاعب الألة. بحيث تكون الأفضلية له عن طريق تقليل حظ الخصم في الفوز وزيادة حظ لاعب الألة. علاوة على ذلك، خوارزمية ألفا بيتا ننخذ مسار اقصر في البحث عن طريق قطع اجزاء من الشجرة. تلك التي لاحظ انها لن تقدم له شيء يغير في نتيجة عملية البحث. مثال بسيط على ذلك، انظر شكل2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=alphaBetaExample.png width=550 leight=550>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As saw in the previous example. The alpha beta algorithm uses the DFS to search.  Max represents the machine player, where Min represents the opponent. At the end of the trees you will see numbers. These numbers represent the board quality for the Max player, and these numbers come from the `evaluation_function`. As for the cut that happened below the Min player in the state bearing number 2, this happened because Max player was looking for a number higher than the number it had(4), And Min player got a smaller number, and because Min player searches for the lowest number. This also applies to the cut that happened in the other Min. In the end it will get the best move for the Max player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">كما شاهدنا في المثال السابق. فأن خوارزمية ألفا بيتا تستخدم طريقة أخر داخل أول خارج. ماكس في المثال السابق تمثل دور لاعب الالة بينما مين تمثل الخصم. في اخر الشجر ستجد ارقم، هذه الارقام تمثل جودة اللوح للاعب ماكس، و تحسب هذه الجوة عن طريق وضيفة التقييم. في منتصف الرسم ستجد ان لاعب مين حصل على قطع، و ذلك بسبب ان لاعب ماكس يمتلك رقم(4) و هو يبحث عن رقم اكبر منه، بينما لاعب مين يفعل العكس، فلاعب مين حصل على رقم 2 فالبتاكيد لاعب مين لن يعطي لاعب ماكس رقم اعلى من الذي هو يمتلكه، فالذلك نحن لا نحتاج للبحث اكثر من ذلك. هذا ايضا ينطبق على الجز الاخير. في النهاية سوف يحصل لاعب ماكس على افضل حركة يمكنه ان يتخذها."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose a Connect Four game to be implemented with the alpha-beta algorithm. This implementation in Python language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">أخترنا لعبة ربط أربعة لننفذها بواسطة خوارزمية ألفا بيتا. هذا تنفيذ عليها بلغة البايثون."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load test1.txt\n",
    "# input for test case 1 \n",
    ".......\n",
    ".......\n",
    ".......\n",
    "..Y....\n",
    "..R...Y\n",
    "..RYRYR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load test2.txt\n",
    "# input for test case 2\n",
    ".......\n",
    ".......\n",
    ".......\n",
    ".......\n",
    "......Y\n",
    "...YRYR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best move to R player:\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m_______________________________\n",
      "best move to Y player:\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m_______________________________\n",
      "best move to R player:\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m_______________________________\n",
      "\u001b[1;31;40m** RED won **\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# This evaluation is based on the location\n",
    "evaluation_array = [[3, 4,  5,  7,  5, 4, 3],\n",
    "                    [4, 6,  8, 10,  8, 6, 4],\n",
    "                    [5, 8, 11, 13, 11, 8, 5],\n",
    "                    [5, 8, 11, 13, 11, 8, 5],\n",
    "                    [4, 6,  8, 10,  8, 6, 4],\n",
    "                    [3, 4,  5,  7,  5, 4, 3]]\n",
    "\n",
    "\n",
    "YELLOW  = '\\033[1;33;40m'\n",
    "RED    = '\\033[1;31;40m'\n",
    "WHITE   = '\\033[1;37;40m'\n",
    "\n",
    "\n",
    "alpha = -10000\n",
    "beta = 10000\n",
    "depth = 6\n",
    "\n",
    "def evaluation_function(state):\n",
    "    f = 0\n",
    "    for row in range(6):\n",
    "        for column in range(7):\n",
    "            if state[row][column] == 'R' :\n",
    "                f += evaluation_array[row][column]\n",
    "            elif state[row][column] == 'Y':\n",
    "                f -= evaluation_array[row][column]\n",
    "    #  print(f)\n",
    "    #  print('_______________________________')\n",
    "    return f\n",
    "\n",
    "\n",
    "def create_state(state, player):\n",
    "    state_list = []\n",
    "    for column in range(7):\n",
    "        if not full_column(state, column):\n",
    "            state_list.append(put(state, column, player))\n",
    "    return state_list\n",
    "\n",
    "\n",
    "def win(state, player):\n",
    "    player_win = False\n",
    "    for row in range(6):\n",
    "        for column in range(7):\n",
    "            if state[row][column] == player:\n",
    "                player_win = is_four(state, row, column, player)\n",
    "            if player_win:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# check if the player has four points together\n",
    "def is_four(state, row, column, player):\n",
    "    if row >= 3:\n",
    "        if state[row - 3][column] == player and state[row - 2][column] == player and state[row - 1][column] == player:\n",
    "            return True\n",
    "        if column >= 3:\n",
    "            if state[row - 3][column - 3] == player and state[row - 2][column - 2] == player and state[row - 1][column - 1] == player:\n",
    "                return True\n",
    "        if 6 - column >= 3:\n",
    "            if state[row - 3][column + 3] == player and state[row - 2][column + 2] == player and state[row - 1][column + 1] == player:\n",
    "                return True\n",
    "    if 5 - row >= 3:\n",
    "        if state[row + 3][column] == player and state[row + 2][column] == player and state[row + 1][column] == player:\n",
    "            return True\n",
    "        if column >= 3:\n",
    "            if state[row + 3][column - 3] == player and state[row + 2][column - 2] == player and state[row + 1][column - 1] == player:\n",
    "                return True\n",
    "        if 6 - column >= 3:\n",
    "            if state[row + 3][column + 3] == player and state[row + 2][column + 2] == player and state[row + 1][column + 1] == player:\n",
    "                return True\n",
    "    if column >= 3:\n",
    "        if state[row][column - 3] == player and state[row][column - 2] == player and state[row][column - 1] == player:\n",
    "            return True\n",
    "    if 6 - column >= 3:\n",
    "        if state[row][column + 3] == player and state[row][column + 2] == player and state[row][column + 1] == player:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def put(state, column, player):\n",
    "    state_copy = copy(state)\n",
    "    for row in reversed(range(6)):\n",
    "        if state_copy[row][column] == '.':\n",
    "            state_copy[row][column] = player\n",
    "            break\n",
    "    return state_copy\n",
    "\n",
    "\n",
    "def copy(state):\n",
    "    s = [[], [], [], [], [], []]\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            s[i].append(state[i][j])\n",
    "    return s\n",
    "\n",
    "\n",
    "# This method show if the board is full\n",
    "def full_board(state):\n",
    "    for column in range(7):\n",
    "        if not full_column(state, column):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def full_column(state, column):\n",
    "    if state[0][column] == 'Y' or state[0][column] == 'R':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def maximum(x, y):\n",
    "    if x > y:\n",
    "        return x\n",
    "    else:\n",
    "        return y\n",
    "\n",
    "\n",
    "def minimum(x, y):\n",
    "    if x < y:\n",
    "        return x\n",
    "    else:\n",
    "        return y\n",
    "\n",
    "\n",
    "def print_board(state):\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if state[i][j] == 'Y':\n",
    "                print(WHITE + '|' + ' ' + YELLOW + state[i][j] + ' ', end= '')\n",
    "            elif state[i][j] == 'R':\n",
    "                print(WHITE +'|'+ ' '+ RED  + state[i][j] + ' ', end='')\n",
    "            elif state[i][j] == '.':\n",
    "                print(WHITE +'|   ', end = '') \n",
    "        \n",
    "        print('|')\n",
    "            \n",
    "    print(WHITE +'_______________________________')\n",
    "\n",
    "def print_board2(state):\n",
    "    print(state[0])\n",
    "    print(state[1])\n",
    "    print(state[2])\n",
    "    print(state[3])\n",
    "    print(state[4])\n",
    "    print(state[5])\n",
    "\n",
    "def alpha_beta_search(state, alpha, beta, depth, turn):\n",
    "    #  print(f'{alpha} <= {beta}')\n",
    "    #  print_board(state)\n",
    "    if turn == 'R':\n",
    "        depth -= 1\n",
    "        value = -10000\n",
    "        list_value = []\n",
    "        list = create_state(state, 'R')\n",
    "        for s in list:\n",
    "            min_v = min_value(s, alpha, beta, depth)\n",
    "            value = maximum(value, min_v)\n",
    "            list_value.append(min_v)\n",
    "            if value >= beta:\n",
    "                break\n",
    "            alpha = maximum(alpha, value)\n",
    "        for i in range(len(list)):\n",
    "            if value == list_value[i]:\n",
    "                #  print_board(list[i])\n",
    "                return list[i]\n",
    "    else:\n",
    "        depth -= 1\n",
    "        value = 10000\n",
    "        list_value = []\n",
    "        list = create_state(state, 'Y')\n",
    "        for s in list:\n",
    "            min_v = max_value(s, alpha, beta, depth)\n",
    "            value = minimum(value, min_v)\n",
    "            list_value.append(min_v)\n",
    "            if value <= alpha:\n",
    "                break\n",
    "            alpha = minimum(alpha, value)\n",
    "        for i in range(len(list)):\n",
    "            if value == list_value[i]:\n",
    "                #  print_board(list[i])\n",
    "                return list[i]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def max_value(state, alpha, beta, depth):\n",
    "    #  print(f'{alpha} <= {beta}')\n",
    "    #  print_board(state)\n",
    "    if win(state, 'Y'):\n",
    "        return -10000\n",
    "    elif full_board(state):\n",
    "        return 0\n",
    "    elif depth == 0:\n",
    "        return evaluation_function(state)\n",
    "\n",
    "    depth -= 1\n",
    "    value = -10000\n",
    "    list = create_state(state, 'R')\n",
    "    for s in list:\n",
    "        value = maximum(value, min_value(s, alpha, beta, depth))\n",
    "        if value >= beta:\n",
    "            return value\n",
    "        alpha = maximum(alpha, value)\n",
    "    return value\n",
    "\n",
    "\n",
    "def min_value(state, alpha, beta, depth):\n",
    "    #  print(f'{alpha} <= {beta}')\n",
    "    #  print_board(state)\n",
    "    if win(state, 'R'):\n",
    "        return 10000\n",
    "    elif full_board(state):\n",
    "        return 0\n",
    "    elif depth == 0:\n",
    "        return evaluation_function(state)\n",
    "\n",
    "    depth -= 1\n",
    "    value = 10000\n",
    "    list = create_state(state, 'Y')\n",
    "    for s in list:\n",
    "        value = minimum(value, max_value(s, alpha, beta, depth))\n",
    "        if value <= alpha:\n",
    "            return value\n",
    "        beta = minimum(beta, value)\n",
    "    return value\n",
    "\n",
    "\n",
    "#  max = B, min = Y\n",
    "current_state = []\n",
    "\n",
    "for line in open(\"test4.txt\"):\n",
    "    line=line.strip()\n",
    "    current_state.append([str(c) for c in line])\n",
    "\n",
    "# current_state = [[' ', ' ', ' ', ' ', ' ', ' ', ' '],\n",
    "#                  [' ', ' ', ' ', ' ', ' ', ' ', ' '],\n",
    "#                  [' ', ' ', ' ', ' ', ' ', ' ', ' '],\n",
    "#                  [' ', ' ', ' ', ' ', ' ', ' ', ' '],\n",
    "#                  [' ', ' ', ' ', 'Y', ' ', ' ', 'Y'],\n",
    "#                  [' ', ' ', 'R', 'Y', 'R', 'Y', 'R']]\n",
    "\n",
    "# print(current_state)\n",
    "turn  = 'R'\n",
    "\n",
    "while(True):\n",
    "\n",
    "    if win(current_state, 'Y'):\n",
    "        print(YELLOW +'** Yellow won **')\n",
    "        break\n",
    "    elif win(current_state, 'R'):\n",
    "        print(RED +'** RED won **')\n",
    "        break\n",
    "    elif full_board(current_state):\n",
    "        print('The board is full')\n",
    "        print ('Tie')\n",
    "        break\n",
    "\n",
    "    temp1 = alpha_beta_search(current_state, alpha, beta, depth, turn)\n",
    "    print('best move to '+turn+' player:')\n",
    "    print_board(temp1)\n",
    "\n",
    "    if turn == 'R':\n",
    "        turn = 'Y'\n",
    "    else:\n",
    "        turn = 'R'\n",
    "\n",
    "    current_state = temp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the previous implementation, R is the abbreviation of red, and it represents the role of the machine player, and Y is the abbreviation of yellow, and it represents the role of the opponent. At the beginning of each step, we check whether the previous player won or if the board became full, because if it was, we do not need to continue. For 10,000 and -10000 it represents ∞ and -∞, why is that number exactly? Because it is not possible to have a number that is close to it, no matter if we add all the numbers in the evaluation board, it represents ∞ for this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">كما شاهدة في التنفيذ السابق، فأن حرف أر هو أختصار للون الأحمر وهو يمثل دور لاعب الألة، اما بالنسبة لحرف واي فهو أختصار للون الأصفر وهو يمثل دور الخصم. في بداية كل خطوة، نتحقق من اذا كان اللاعب السابق فاز في اللعبة، او أن اللوح أصبح ممتلى، لانه أذا كان كذلك فلسنا بحاجه الى ان نكمل. بالنسبة ل(10000 و -10000) فهي تمثل ∞ و -∞. لماذا هذا الرقم بالتحديد؟ لانه لايمكن الوصول اليه مهما جمعنا جميع الاراقم الموجودة في لوح التقييم."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color = #0F43B4>V-Examples </font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some examples of how the alpha-beta algorithm can work on Connect Four game. First, let's see a simple example of this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">لنشاهد بعض الامثلة التي قد تقطينا صور عن كيفية عمل خوارزمية ألفا بيتا على لعبة ربط أربعة. في البداية سناخذ مثال بسيط على هذا الموضوع."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Example 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, suppose the depth reaches even the third level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">في هذا المثال ، افترض أن العمق سيصل حتى إلى المستوى الثالث."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=EX1_1.png width=150 leight=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the current state of the board where the machine player will search for the next move using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">هذه الحالة الحالية للوح حيث سيبحث لاعب الألة عن الحركة التالية بأستخدامها."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex1.2.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose Level 3 to be the last depth we can reach. number 12 came from `evaluation_function`. Max represents the machine player, where Min represents the opponent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">لقد اخترنا المستوى 3 ليكون العمق الأخير الذي يمكننا الوصول إليه. الرقم 12 جاء من وظيفة_التقييم. يمثل ماكس لاعب الآلة ، حيث يمثل مين الخصم."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex1.3.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got ∞ because this movement will make the Max player win. Since the Max player will choose the best move for its (the highest number). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">لقد حصلنا ∞ لأن هذه الحركة ستجعل لاعب ماكس يفوز. نظرًا لأن لاعب ماكس سيختار أفضل حركة له (أعلى رقم)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex1.4.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min player is an opponent, it works to make the Max player loses the game by choosing that move which will not make the Max player win. how can do that? By choosing the lowest value from the sub-state set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">لاعب مين هو الخصم فهو يحاول ان يدفع لاعب ماكس الى الخسارة. كيف يمكن ذلك؟ عن طريق اختيار لاعب مين لاقل قيمة."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex1.5.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situation, the alpha-beta algorithm cut the rest of the tree, because the value that the Max player got is greater or equal to the beta value it owns. This situation calls beta-cut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">في هذه الحالة خوارزمية ألفا بيتا قطعة الشجرة و ذلك بسب ان القيمة التي حصل علية لاعب ماكس اكبر او تساوي قيمة بيتا التي يمتلكها. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex1.6.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened here is exactly what happened in the previous figure. The alpha-beta algorithm cut the rest of the tree, because the value that the Max player got is greater or equal to the beta value it owns. Now from this graph, you can see what step Max player should take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">ما حدث هنا هو بالضبط ما حدث في الشكل السابق. خوارزمية ألفا بيتا قطعة الشجرة و ذلك بسب ان القيمة التي حصل علية لاعب ماكس اكبر او تساوي قيمة بيتا التي يمتلكها. الآن من هذا الرسم، يمكنك معرفة الخطوة التي يجب أن يتخذها لاعب ماكس. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply to the previous example using the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load test3.txt\n",
    "# Input for example 1 \n",
    "RY.YY.R\n",
    "RY.RY.Y\n",
    "YY.YR.Y\n",
    "YR.RY.Y\n",
    "YR.RR.R\n",
    "RY.RR.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example1: The current state \n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m_______________________________\n",
      "best move to R player:\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m_______________________________\n",
      "best move to Y player:\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m_______________________________\n",
      "best move to R player:\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m_______________________________\n",
      "\u001b[1;31;40m** RED won **\n"
     ]
    }
   ],
   "source": [
    "#R is red and Y is yellow\n",
    "alpha = -10000\n",
    "beta = 10000\n",
    "depth = 3\n",
    "turn = 'R'\n",
    "\n",
    "\n",
    "current_state = []\n",
    "c = 0\n",
    "for line in open(\"test3.txt\"):\n",
    "    line=line.strip()\n",
    "    current_state.append([str(c) for c in line])\n",
    "\n",
    "#current_state = [['R', 'Y', ' ', 'Y', 'Y', ' ', 'R'],\n",
    "#                ['R', 'Y', ' ', 'R', 'Y', ' ', 'Y'],\n",
    "#                ['Y', 'Y', ' ', 'Y', 'R', ' ', 'Y'],\n",
    "#                ['Y', 'R', ' ', 'R', 'Y', ' ', 'Y'],\n",
    "#                ['Y', 'R', ' ', 'R', 'R', ' ', 'R'],\n",
    "#                ['R', 'Y', ' ', 'R', 'R', ' ', 'R']]\n",
    "\n",
    "#\n",
    "print('Example1: The current state ')\n",
    "print_board(current_state)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    if win(current_state, 'Y'):\n",
    "        print(YELLOW +'** Yellow won **')\n",
    "        break\n",
    "    elif win(current_state, 'R'):\n",
    "        print(RED +'** RED won **')\n",
    "        break\n",
    "    elif full_board(current_state):\n",
    "        print('The board is full')\n",
    "        break\n",
    "\n",
    "    temp1 = alpha_beta_search(current_state, alpha, beta, depth, turn)\n",
    "    print('best move to '+turn+' player:')\n",
    "    print_board(temp1)\n",
    "\n",
    "    if turn == 'R':\n",
    "        turn = 'Y'\n",
    "    else:\n",
    "        turn = 'R'\n",
    "\n",
    "    current_state = temp1\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Example 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, suppose the depth reaches even the second level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">في هذا المثال ، افترض أن العمق يصل حتى المستوى الثاني."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex2.1.png width=150 leight=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the current state of the board where the Max player will search for the next move using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">هذه الحالة الحالية للوح حيث سيبحث لاعب ماكس عن الحركة التالية بأستخدامها."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex2.2.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose Level 2 to be the last depth we can reach. The value became -∞ because the opponent won."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">لقد اخترنا المستوى 2 ليكون العمق الأخير الذي يمكننا الوصول إليه. أصبحت القيمة ∞- لأن الخصم فاز."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex2.3.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situation, the alpha-beta algorithm cut the rest of the tree, because the value that the Min player got is Smaller or equal to the alpha value it owns. This situation calls alpha-cut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">في هذه الحالة ، تقوم خوارزمية ألفا بيتا بقطع باقي الشجرة ، لأن القيمة التي حصل عليها لاعب مين هي أصغر أو تساوي قيمة ألفا التي يمتلكها. تسمى هذا الحالة قطع ألفا."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex2.4.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex2.5.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex2.6.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ex2.7.png width=700 leight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got ∞ because this movement will make the Max player win. Since the Max player will choose the best move for its (the highest number). It also does not need to search more, because the Max player has already won."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">لقد حصلنا ∞ لأن هذه الحركة ستجعل لاعب ماكس يفوز. نظرًا لأن لاعب ماكس سيختار أفضل حركة له (أعلى رقم). كما أن خوارزمية ألفا بيتا لا تحتاج إلى البحث أكثر ، لأن لاعب ماكس قد فاز بالفعل."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply to the previous example using the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load test4.txt\n",
    "# Input for example 2 :\n",
    "RY.R..R\n",
    "YY.Y.RY\n",
    "YR.Y.RY\n",
    "RY.Y.RR\n",
    "YR.R.YR\n",
    "RY.YRYR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example2: The current state \n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m_______________________________\n",
      "best move to R player:\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m|   \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR \u001b[1;37;40m| \u001b[1;33;40mY \u001b[1;37;40m| \u001b[1;31;40mR |\n",
      "\u001b[1;37;40m_______________________________\n",
      "\u001b[1;31;40m** RED won **\n"
     ]
    }
   ],
   "source": [
    "#R is red and Y is yellow\n",
    "alpha = -10000\n",
    "beta = 10000\n",
    "depth = 2\n",
    "turn = 'R'\n",
    "current_state = []\n",
    "c = 0\n",
    "for line in open(\"test4.txt\"):\n",
    "    line=line.strip()\n",
    "    current_state.append([str(c) for c in line])\n",
    "\n",
    "# current_state = [['R', 'Y', ' ', 'R', ' ', ' ', 'R'],\n",
    "#                  ['Y', 'Y', ' ', 'Y', ' ', 'R', 'Y'],\n",
    "#                  ['Y', 'R', ' ', 'Y', ' ', 'R', 'Y'],\n",
    "#                  ['R', 'Y', ' ', 'Y', ' ', 'R', 'R'],\n",
    "#                  ['Y', 'R', ' ', 'R', ' ', 'Y', 'R'],\n",
    "#                  ['R', 'Y', ' ', 'Y', 'R', 'Y', 'R']]\n",
    "print('Example2: The current state ')\n",
    "print_board(current_state)\n",
    "\n",
    "\n",
    "while(True):\n",
    "\n",
    "    if win(current_state, 'Y'):\n",
    "        print(YELLOW +'** Yellow won **')\n",
    "        break\n",
    "    elif win(current_state, 'R'):\n",
    "        print(RED +'** RED won **')\n",
    "        break\n",
    "    elif full_board(current_state):\n",
    "        print('The board is full')\n",
    "        break\n",
    "        \n",
    "    temp1 = alpha_beta_search(current_state, alpha, beta, depth, turn)\n",
    "    print('best move to '+turn+' player:')\n",
    "    print_board(temp1)\n",
    "\n",
    "    if turn == 'R':\n",
    "        turn = 'Y'\n",
    "    else:\n",
    "        turn = 'R'\n",
    "\n",
    "    current_state = temp1\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color = #0F43B4>VI-Implementation</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will take an overview of the implementation of this problem. The whole implementation in Python language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">في هذا الجزء سوف ناخذ نظره على التنفيذ لهاذ المشكلة. هذا المشروع تم تنفيذه بلغة البايثون بالكامل."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state(state, player):\n",
    "    state_list = []\n",
    "    for column in range(7):\n",
    "        if not full_column(state, column):\n",
    "            state_list.append(put(state, column, player))\n",
    "    return state_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_state` is a simple function that creates a list of all available statuses that a player can take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">هي وضيفه تخلق مجموعة من الطرق التي من الممكن ان يتخذها اللاعب.`create_state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_board(state):\n",
    "    for column in range(7):\n",
    "        if not full_column(state, column):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def full_column(state, column):\n",
    "    if state[0][column] == ' ':\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions are used to check the status where `full_board` checks the whole board, while `full_column` checks only one column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">هذه الدالتان تتحق من حالة اللوح حيث الاولا تتاكد من اللوح بالكامل و الاخر تتاكد من عمود واحد فقط."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win(state, player):\n",
    "    player_win = False\n",
    "    for row in range(6):\n",
    "        for column in range(7):\n",
    "            if state[row][column] == player:\n",
    "                player_win = is_four(state, row, column, player)\n",
    "            if player_win:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# check if the player has four points together vertically, horizontally, or diagonally\n",
    "def is_four(state, row, column, player):\n",
    "    if row >= 3:\n",
    "        if state[row-3][column]==player and state[row-2][column]==player and state[row-1][column]==player:\n",
    "            return True\n",
    "        if column >= 3:\n",
    "            if state[row-3][column-3]==player and state[row-2][column-2]==player and state[row-1][column-1]==player:\n",
    "                return True\n",
    "        if 6 - column >= 3:\n",
    "            if state[row-3][column+3]==player and state[row-2][column+2]==player and state[row-1][column+1]==player:\n",
    "                return True\n",
    "    if 5 - row >= 3:\n",
    "        if state[row+3][column]==player and state[row+2][column]==player and state[row+1][column]==player:\n",
    "            return True\n",
    "        if column >= 3:\n",
    "            if state[row+3][column-3]==player and state[row+2][column-2]==player and state[row+1][column-1]==player:\n",
    "                return True\n",
    "        if 6 - column >= 3:\n",
    "            if state[row+3][column+3]==player and state[row+2][column+2]==player and state[row+1][column+1]==player:\n",
    "                return True\n",
    "    if column >= 3:\n",
    "        if state[row][column-3]==player and state[row][column-2]==player and state[row][column-1]==player:\n",
    "            return True\n",
    "    if 6 - column >= 3:\n",
    "        if state[row][column+3]==player and state[row][column+2]==player and state[row][column+1]==player:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions work together. We use it to check whether the player won or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">تعمل هاتان الوظيفتان معًا. نستخدمها للتحقق مما إذا كان اللاعب فاز أم لا."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum(x, y):\n",
    "    if x > y:\n",
    "        return x\n",
    "    else:\n",
    "        return y\n",
    "\n",
    "\n",
    "def minimum(x, y):\n",
    "    if x < y:\n",
    "        return x\n",
    "    else:\n",
    "        return y\n",
    "\n",
    "\n",
    "def print_board(state):\n",
    "    print('_____________________________')\n",
    "    for row in range(6):\n",
    "        s = '| '\n",
    "        for column in range(7):\n",
    "            s = s + state[row][column] + ' | '\n",
    "        print(s)\n",
    "        print('_____________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those simple functions where `maximum` and `minimum` return the maximum and minimum values. `print_board` is a function that shows a board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">هذه الوظائف بسيطة حيث اول وضيفتان ترجعان القيم القصوى والدنيا.اما بالنسبة للاخر فهي تظهر اللوح."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color = #0F43B4> VII-Conclusion</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =  #0F43B4><h2> Proformance </h2></font>\n",
    "<li>  Worst case: no pruning, same as Minimax (O(b^d))\n",
    "<li> Best case: when each player’s best move is the first option examined, you examine only O(b^d/2)nodes.  \n",
    "<li>  Guaranteed to compute same root value as Minimax\n",
    "    </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem grows exponential, as in the worst case we can extract seven board cases from the current state, add to that that the depth will be up to the forty-second level. But let's assume that the search algorithm will search up to the tenth level, suppose also that it needs one millisec for every node, that would make its need to((7^10)10msec = 282475.25sec = 3.27days). Well now you can see how much we need to reduce search time. Because of that, we are using the alpha_beta algorithm and not the Minimax algorithm, because it shortens the search by pruning the search tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">هذه المشكلة تكبر أسيًا حيث أن في أسوء الاحوال نستطيع أن نستخرج سبع حالات للوح من الحالة الحالية له، أضف على ذلك أن العمق سيكون حتى المستوى الثاني وأربعون. لكن لنفترض أن خوارزمية البحث ستصل حى المستوى العاشر فقط، و لنفترض ايضا انها تحتاج ملي ثانية واحدة فقط من اجل كل حالة. ذلك سيجعلها تحتاج ما يقارب ثلاثة ايام و ربع، فلك ان تتخيل ذلك. حسنا يمكنك الان ان تعرف الى اي مدى حقا تحتاج خوارزميات البحث الى تقليل ذلك.<br> و هذا احد الاسباب التي جعلتنا ان نستخدم خوارزمية ألفا بيتا وليس خوارزمية مين ماكس، لانها تختصر عملية البحث عن طريق قطع اجزاء من شجرة البحث تلك التي لا تحتاجها.                        بالنسبة الى ما مدى جودة خطوة لاعب ماكس فهو في الواقع يعتمد على شيئين، الاول هو العمق فالى اي عمق يستطيع الوصول اليه، و الشيء الاخر هو  وضيفة التقييم. فكلما كان العمق يستطيع الذهاب اعمق فكلما كانت النتيجة افضل، لكن هذا سيكلف الخوارزمية في وقت البحث. اما بالنسبة الى وضيفة التقييم فكلما كانت دقيقة كلما قدم لاعب ماكس ذكاء أعلى."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> O(b^d) اسؤ حالة : لا يوجد تقطيع مشابها لي مين ماكس\n",
    "<li> O (b^d/2) افضل حالة : عندما تكون افضل حركة هي اول حركة و بذالك نفحص فقط \n",
    "<li> يضمن ان يحسب قيمة الروت نفس مين ماكس     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
